{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Deep Computer Vision Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the advantages of a CNN over a fully connected DNN for image classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameter efficiency: Parameters are reused over the image\n",
    "* Invariance: Patterns learned somewhere in an image are detected everywhere\n",
    "* Locality: CNNs can be constructed to combine low-level features into larger structures by chaining multiple CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3 input layers, 3 x 3 kernel, bias , 100 output maps -> (3 x 3 x 3 + 1) x 100 = 2800 parameters \n",
    "* 100 input layers, 3 x 3 kernel, bias, 200 output maps -> (100 x 3 x 3 + 1) x 200 = 180200 parameters\n",
    "* 200 input layers, 3 x 3 kernel, bias , 400 output maps -> (200 x 3 x 3 + 1) x 400 = 720400 parameters\n",
    "* Total parameters = 2800 + 180200 + 720400 = 903'400 parameters\n",
    "\n",
    "For inference, only two consecutive layers need to be retained in memory:\n",
    "* Same padding + stride 2: input channel 200 x 300 -> first feature map 100 x 150 -> second feature map 50 x 75 -> third feature map 25 x 38\n",
    "* 32 bits = 4 bytes\n",
    "* First layer: 4 x 100 x 100 x 150 = 6'000'000 = 6mb\n",
    "* Second layer: 4 x 200 x 50 x 75 = 3'000'000 = 3mb\n",
    "* third layer: 4 x 400 x 25 x 38 = 1'520'000 = 1.52mb\n",
    "* Assuming optimization (only two consecutive layers in memory), inference will require 9mb of RAM for the feature maps, plus 903'400 parameters ~ 3.6mb, plus the image itself, 4 * 200 * 300 x 3 pixels ~ 720kb\n",
    "\n",
    "For training, all layers need to be stored in memory for the backward pass:\n",
    "* The layers together require 6 + 3 + 1.6 = 10.5 mb\n",
    "* For a batch size of 50, 10.5 * 50 = 525mb\n",
    "* Size of images: 50 * 720kb = 36mb\n",
    "* Model parameters: 3.6 mb\n",
    "* Minimum RAM for training: 525 + 36 + 3.6 = 564.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increase stride\n",
    "* Use consecutive 3x3 kernels, rather than 5x5 or 7x7 kernels\n",
    "* Smaller batch size\n",
    "* Reduce size of data to 16bits or even 8 bits\n",
    "* More maxpooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fewer parameters to learn\n",
    "* Max pooling reinforces most dominant signal and removes noise -> acts as regularizer and improves generalization performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When would you want to add a local response normalization layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To force different feature maps to learn/explore a wider range of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AlexNet: Stack convolutional layers directly on top of one another + local response normalization\n",
    "* GoggLeNet: Inception modules\n",
    "* ResNet: Residual learning / skip connections\n",
    "* Xception: Depthwise separable convolution layer\n",
    "* SENet: SE block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A neural network composed only of convolution and pooling layers\n",
    "* Replace first dense layer with a convolution layer with kernal size equal to layer's input size, stride 1, and \"valid\" padding. The following layers need 1x1 filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the main technical difficulty of semantic segmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information loss in CNNs. Pixel-level information needs to be restored for the final task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full,  y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000]/255., X_train_full[5000:]/255.\n",
    "y_valid, y_train= y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis].astype('float32')\n",
    "X_valid = X_valid[..., np.newaxis].astype('float32')\n",
    "X_test = X_test[..., np.newaxis].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'nadam', metrics=['accuracy', 'categorical_accuracy', 'sparse_top_k_categorical_accuracy', 'top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4312), started 4:03:23 ago. (Use '!kill 4312' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3d70e44757732dda\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3d70e44757732dda\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint_cb = keras.callbacks.ModelCheckpoint('./models/my_mnist_cnn.h5', save_best_only=True)\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [modelcheckpoint_cb, earlystopping_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   1/1719 [..............................] - ETA: 0s - loss: 2.3051 - accuracy: 0.1562 - categorical_accuracy: 0.4688 - sparse_top_k_categorical_accuracy: 0.5312 - top_k_categorical_accuracy: 0.9062WARNING:tensorflow:From C:\\Users\\Philipp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1719 [..............................] - ETA: 4:36 - loss: 2.2864 - accuracy: 0.1719 - categorical_accuracy: 0.2656 - sparse_top_k_categorical_accuracy: 0.5938 - top_k_categorical_accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.3193s). Check your callbacks.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3878 - accuracy: 0.8791 - categorical_accuracy: 0.1012 - sparse_top_k_categorical_accuracy: 0.9804 - top_k_categorical_accuracy: 0.3939 - val_loss: 0.0621 - val_accuracy: 0.9838 - val_categorical_accuracy: 0.0962 - val_sparse_top_k_categorical_accuracy: 0.9986 - val_top_k_categorical_accuracy: 0.3202\n",
      "Epoch 2/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1353 - accuracy: 0.9645 - categorical_accuracy: 0.0992 - sparse_top_k_categorical_accuracy: 0.9971 - top_k_categorical_accuracy: 0.3875 - val_loss: 0.0402 - val_accuracy: 0.9890 - val_categorical_accuracy: 0.0964 - val_sparse_top_k_categorical_accuracy: 0.9998 - val_top_k_categorical_accuracy: 0.2868\n",
      "Epoch 3/200\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1026 - accuracy: 0.9737 - categorical_accuracy: 0.0994 - sparse_top_k_categorical_accuracy: 0.9983 - top_k_categorical_accuracy: 0.3633 - val_loss: 0.0496 - val_accuracy: 0.9886 - val_categorical_accuracy: 0.0954 - val_sparse_top_k_categorical_accuracy: 1.0000 - val_top_k_categorical_accuracy: 0.2226\n",
      "Epoch 4/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0811 - accuracy: 0.9795 - categorical_accuracy: 0.0994 - sparse_top_k_categorical_accuracy: 0.9989 - top_k_categorical_accuracy: 0.3546 - val_loss: 0.0271 - val_accuracy: 0.9922 - val_categorical_accuracy: 0.0964 - val_sparse_top_k_categorical_accuracy: 0.9998 - val_top_k_categorical_accuracy: 0.2434\n",
      "Epoch 5/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0695 - accuracy: 0.9819 - categorical_accuracy: 0.0993 - sparse_top_k_categorical_accuracy: 0.9989 - top_k_categorical_accuracy: 0.3340 - val_loss: 0.0388 - val_accuracy: 0.9926 - val_categorical_accuracy: 0.0960 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.2494\n",
      "Epoch 6/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0629 - accuracy: 0.9836 - categorical_accuracy: 0.0992 - sparse_top_k_categorical_accuracy: 0.9989 - top_k_categorical_accuracy: 0.3383 - val_loss: 0.0324 - val_accuracy: 0.9928 - val_categorical_accuracy: 0.0962 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.2078\n",
      "Epoch 7/200\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0558 - accuracy: 0.9848 - categorical_accuracy: 0.0993 - sparse_top_k_categorical_accuracy: 0.9992 - top_k_categorical_accuracy: 0.3194 - val_loss: 0.0306 - val_accuracy: 0.9932 - val_categorical_accuracy: 0.0964 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.2048\n",
      "Epoch 8/200\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0487 - accuracy: 0.9866 - categorical_accuracy: 0.0991 - sparse_top_k_categorical_accuracy: 0.9992 - top_k_categorical_accuracy: 0.3151 - val_loss: 0.0518 - val_accuracy: 0.9912 - val_categorical_accuracy: 0.0966 - val_sparse_top_k_categorical_accuracy: 0.9998 - val_top_k_categorical_accuracy: 0.2042\n",
      "Epoch 9/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0463 - accuracy: 0.9876 - categorical_accuracy: 0.0990 - sparse_top_k_categorical_accuracy: 0.9993 - top_k_categorical_accuracy: 0.3338 - val_loss: 0.0396 - val_accuracy: 0.9928 - val_categorical_accuracy: 0.0964 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.1980\n",
      "Epoch 10/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0412 - accuracy: 0.9885 - categorical_accuracy: 0.0989 - sparse_top_k_categorical_accuracy: 0.9995 - top_k_categorical_accuracy: 0.3230 - val_loss: 0.0487 - val_accuracy: 0.9898 - val_categorical_accuracy: 0.0958 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.1986\n",
      "Epoch 11/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0392 - accuracy: 0.9894 - categorical_accuracy: 0.0991 - sparse_top_k_categorical_accuracy: 0.9995 - top_k_categorical_accuracy: 0.3443 - val_loss: 0.0313 - val_accuracy: 0.9942 - val_categorical_accuracy: 0.0958 - val_sparse_top_k_categorical_accuracy: 0.9998 - val_top_k_categorical_accuracy: 0.2262\n",
      "Epoch 12/200\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0363 - accuracy: 0.9899 - categorical_accuracy: 0.0991 - sparse_top_k_categorical_accuracy: 0.9995 - top_k_categorical_accuracy: 0.3561 - val_loss: 0.0444 - val_accuracy: 0.9942 - val_categorical_accuracy: 0.0962 - val_sparse_top_k_categorical_accuracy: 0.9994 - val_top_k_categorical_accuracy: 0.2112\n",
      "Epoch 13/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0374 - accuracy: 0.9903 - categorical_accuracy: 0.0993 - sparse_top_k_categorical_accuracy: 0.9993 - top_k_categorical_accuracy: 0.3362 - val_loss: 0.0324 - val_accuracy: 0.9932 - val_categorical_accuracy: 0.0962 - val_sparse_top_k_categorical_accuracy: 0.9996 - val_top_k_categorical_accuracy: 0.1918\n",
      "Epoch 14/200\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.0326 - accuracy: 0.9909 - categorical_accuracy: 0.0991 - sparse_top_k_categorical_accuracy: 0.9996 - top_k_categorical_accuracy: 0.3437 - val_loss: 0.0414 - val_accuracy: 0.9934 - val_categorical_accuracy: 0.0960 - val_sparse_top_k_categorical_accuracy: 0.9998 - val_top_k_categorical_accuracy: 0.2088\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_valid, y_valid), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9934 - categorical_accuracy: 0.0960 - sparse_top_k_categorical_accuracy: 0.9998 - top_k_categorical_accuracy: 0.2088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.041420646011829376,\n",
       " 0.993399977684021,\n",
       " 0.09600000083446503,\n",
       " 0.9998000264167786,\n",
       " 0.20880000293254852]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9987 - categorical_accuracy: 0.0991 - sparse_top_k_categorical_accuracy: 1.0000 - top_k_categorical_accuracy: 0.2107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004471472930163145,\n",
       " 0.9987454414367676,\n",
       " 0.09907272458076477,\n",
       " 0.9999818205833435,\n",
       " 0.21067272126674652]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.0964 - categorical_accuracy: 0.0964 - sparse_top_k_categorical_accuracy: 0.9998 - top_k_categorical_accuracy: 0.2434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02713191509246826,\n",
       " 0.09640000015497208,\n",
       " 0.09640000015497208,\n",
       " 0.9998000264167786,\n",
       " 0.2433999925851822]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load = keras.models.load_model('./models/my_mnist_cnn.h5')\n",
    "model_load.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0173 - accuracy: 0.0990 - categorical_accuracy: 0.0990 - sparse_top_k_categorical_accuracy: 0.9998 - top_k_categorical_accuracy: 0.2377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.017329227179288864,\n",
       " 0.09901817888021469,\n",
       " 0.09901817888021469,\n",
       " 0.9998363852500916,\n",
       " 0.23772726953029633]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983636363636363"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_train), axis=-1)\n",
    "sum(y_train == y_pred) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987454545454545"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model_load.predict(X_train), axis=-1)\n",
    "sum(y_train == y_pred) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model_load.predict(X_valid), axis=-1)\n",
    "sum(y_valid == y_pred) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_valid), axis=-1)\n",
    "sum(y_valid == y_pred) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./my_mnist_cnn_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = keras.models.load_model('./my_mnist_cnn_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.09600000083446503]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(model.predict(X_valid) == model_test.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.09600000083446503]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = keras.models.load_model('./my_mnist_cnn_test.h5')\n",
    "model_test.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.993399977684021]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.metrics.Mean at 0x182c6d43e08>,\n",
       " <tensorflow.python.keras.metrics.MeanMetricWrapper at 0x182d3c3a248>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.Accuracy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02089118, -0.03093303,  0.05925622,  0.05330097,  0.0412606 ,\n",
       "       -0.01940396, -0.07862163, -0.14383893, -0.57217515,  0.01543191,\n",
       "        0.00902614,  0.04170617, -0.34896886, -0.03886291,  0.02617732,\n",
       "        0.0256169 ,  0.24014159, -0.33885354, -0.07032701,  0.03729414,\n",
       "       -0.02416613, -0.22400498, -0.00736859, -0.13455546,  0.11253003,\n",
       "       -0.12499595,  0.10964944, -0.170484  , -0.18827076, -0.1883732 ,\n",
       "        0.03201261, -0.11146889,  0.29235902,  0.06446967, -0.06647974,\n",
       "       -0.00145599,  0.04357658, -0.00444707, -0.09551448, -0.02749488,\n",
       "        0.03206693, -0.08407733,  0.09534223, -0.14873868, -0.28262717,\n",
       "       -0.15177178,  0.07111242,  0.01771266, -0.03874651, -0.09678347,\n",
       "       -0.00453642, -0.0568822 , -0.02944077, -0.05342673, -0.01625358,\n",
       "       -0.05732775,  0.0736178 ,  0.01949573, -0.07842135, -0.0534521 ,\n",
       "        0.09091351,  0.01105258, -0.02580779, -0.18441854], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02089118, -0.03093303,  0.05925622,  0.05330097,  0.0412606 ,\n",
       "       -0.01940396, -0.07862163, -0.14383893, -0.57217515,  0.01543191,\n",
       "        0.00902614,  0.04170617, -0.34896886, -0.03886291,  0.02617732,\n",
       "        0.0256169 ,  0.24014159, -0.33885354, -0.07032701,  0.03729414,\n",
       "       -0.02416613, -0.22400498, -0.00736859, -0.13455546,  0.11253003,\n",
       "       -0.12499595,  0.10964944, -0.170484  , -0.18827076, -0.1883732 ,\n",
       "        0.03201261, -0.11146889,  0.29235902,  0.06446967, -0.06647974,\n",
       "       -0.00145599,  0.04357658, -0.00444707, -0.09551448, -0.02749488,\n",
       "        0.03206693, -0.08407733,  0.09534223, -0.14873868, -0.28262717,\n",
       "       -0.15177178,  0.07111242,  0.01771266, -0.03874651, -0.09678347,\n",
       "       -0.00453642, -0.0568822 , -0.02944077, -0.05342673, -0.01625358,\n",
       "       -0.05732775,  0.0736178 ,  0.01949573, -0.07842135, -0.0534521 ,\n",
       "        0.09091351,  0.01105258, -0.02580779, -0.18441854], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.layers[0].get_weights()[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(model_test.layers[1].get_weights()[0][0][0][0] == model.layers[1].get_weights()[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.993399977684021]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.09600000083446503]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06746520102024078, 0.09600000083446503]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use transfer learning for large image classification, going through these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training set containing at least 100 images per class. For example, you could classify your own pictures based on the location (beach, mountain, city, etc.), or alternatively you can use an existing dataset (e.g., from TensorFlow Datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split it into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the input pipeline, including the appropriate preprocessing operations, and optionally add data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through TensorFlow’s Style Transfer tutorial. It is a fun way to generate art using Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2 (Python 3.7.8)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
