{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)?\n",
    "* How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A perceptron does a hard classification whereas a logistic regression estimated class probabilities. Estimating class probabilities is often easier and allows for the estimation of confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "If the output of the network is changes to a softmax or a sigmoid function, the perceptron is equivalent to a logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Why was the logistic activation function a key ingredient in training the first\n",
    "MLPs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The logistic activation function is differentiable everywhere and the gradient is never 0. This allows gradient-based optimization to be able to always improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Name three popular activation functions. Can you draw them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Sigmoid: $s(x) = \\frac{1}{1+e^{-x}}$\n",
    "* Tanh: $t(x) = 2s(2x) - 1$\n",
    "* Relu: $r(x) = x^+ = \\max(x,0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s = lambda x: 1 / (1 + np.exp(-x))\n",
    "t = lambda x: 2*s(x) - 1\n",
    "r = lambda x: np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-3,3,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, s(x), 'b-', label='Sigmoid')\n",
    "plt.plot(x, t(x), 'g--', label='tanh')\n",
    "plt.plot(x, r(x), 'r-', label='ReLU')\n",
    "plt.grid(True)\n",
    "plt.axis([-3, 3, -1.2, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "* What is the shape of the input matrix $\\mathbf{X}$?\n",
    "* What are the shapes of the hidden layer’s weight vector $\\mathbf{W}_h$ and its bias vector $\\mathbf{b}_h$?\n",
    "* What are the shapes of the output layer’s weight vector $\\mathbf{W}_o$ and its bias vector $\\mathbf{b}_o$?\n",
    "* What is the shape of the network’s output matrix $\\mathbf{Y}$?\n",
    "* Write the equation that computes the network’s output matrix $\\mathbf{Y}$ as a function of $\\mathbf{X}$, $\\mathbf{W}_h$, $\\mathbf{b}_h$, $\\mathbf{W}_o$, and $\\mathbf{b}_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "$\\mathbf{X}$ is a $m\\times 10$ dimensional matrix, where $m$ is the number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "$\\mathbf{h} = f(\\mathbf{X}\\mathbf{W}_h + \\mathbf{b}_h)$\n",
    "\n",
    "* $\\mathbf{W}_h$ is a $10\\times 50$ dimensional matrix (each column represents the weights from all input nodes to a single node in the hidden layer, each row represents the weights from a single input node to all the hidden nodes)\n",
    "* $\\mathbf{b}_h$ is a $50$-dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "$\\mathbf{Y} = f(\\mathbf{h}\\mathbf{W}_o + \\mathbf{b}_o)$\n",
    "\n",
    "* $\\mathbf{W}_o$ is a $50\\times 3$ dimensiona matrix\n",
    "* $\\mathbf{b}_o$ is a $3$ dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The output matrix $\\mathbf{Y}$ is $m\\times 3$ dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "$\\mathbf{Y} = (\\mathbf{h}\\mathbf{W}_o + \\mathbf{b}_o)^+ = ((\\mathbf{X}\\mathbf{W}_h + \\mathbf{b}_h)^+\\mathbf{W}_o + \\mathbf{b}_o)^+$\n",
    "\n",
    "with the convention that adding a vector to a matrix means that the vector is added to each column of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* How many neurons do you need in the output layer if you want to classify email into spam or ham?\n",
    "* What activation function should you use in the output layer?\n",
    "* If instead you want to tackle MNIST, how many neurons do you need in the output layer, and which activation function should you use?\n",
    "* What about for getting your network to predict housing prices, as in Chapter 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Either use two output nodes with a softmax or a single output node with a sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Use 10 output nodes with softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Use a single node with no activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* What is backpropagation and how does it work?\n",
    "* What is the difference between backpropagation and reverse-mode autodiff?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Backpropagation is an algorithm that calculates the gradient of a neural network by applying the chain-rule for differentiation step-by-step backwards through the network, starting with the loss at the output back to the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Reverse-mode autodiff is an implementation of the backpropagation idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Can you list all the hyperparameters you can tweak in a basic MLP?\n",
    "* If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Learning rate\n",
    "* Optimization algorithm\n",
    "* Number of layers\n",
    "* Nodes per layer\n",
    "* Activation function per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "* Train a deep MLP on the MNIST dataset (you can load it using keras.datasets.mnist.load_data().\n",
    "    - See if you can get over 98% precision.\n",
    "    - Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up).\n",
    "    - Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "num_valid = round(X_train.shape[0] * 0.1)\n",
    "X_valid, X_train = X_train[:num_valid], X_train[num_valid:]\n",
    "y_valid, y_train = y_train[:num_valid], y_train[num_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(14*14, activation='relu'))\n",
    "model.add(keras.layers.Dense(14*7, activation='relu'))\n",
    "model.add(keras.layers.Dense(7*7, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.2245 - accuracy: 0.9348 - val_loss: 0.2166 - val_accuracy: 0.9375\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.2198 - accuracy: 0.9369 - val_loss: 0.2107 - val_accuracy: 0.9380\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.2149 - accuracy: 0.9379 - val_loss: 0.2063 - val_accuracy: 0.9403\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.2102 - accuracy: 0.9392 - val_loss: 0.2025 - val_accuracy: 0.9415\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.2057 - accuracy: 0.9409 - val_loss: 0.1991 - val_accuracy: 0.9432\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.2016 - accuracy: 0.9418 - val_loss: 0.1967 - val_accuracy: 0.9427\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 3s 49us/sample - loss: 0.1975 - accuracy: 0.9434 - val_loss: 0.1929 - val_accuracy: 0.9442\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1936 - accuracy: 0.9442 - val_loss: 0.1894 - val_accuracy: 0.9462\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1899 - accuracy: 0.9455 - val_loss: 0.1854 - val_accuracy: 0.9475\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1861 - accuracy: 0.9470 - val_loss: 0.1831 - val_accuracy: 0.9482\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1827 - accuracy: 0.9476 - val_loss: 0.1802 - val_accuracy: 0.9490\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.1791 - accuracy: 0.9491 - val_loss: 0.1770 - val_accuracy: 0.9498\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1759 - accuracy: 0.9501 - val_loss: 0.1756 - val_accuracy: 0.9507\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1728 - accuracy: 0.9509 - val_loss: 0.1714 - val_accuracy: 0.9523\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1696 - accuracy: 0.9520 - val_loss: 0.1698 - val_accuracy: 0.9518\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1666 - accuracy: 0.9525 - val_loss: 0.1667 - val_accuracy: 0.9522\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1637 - accuracy: 0.9534 - val_loss: 0.1649 - val_accuracy: 0.9538\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1608 - accuracy: 0.9547 - val_loss: 0.1619 - val_accuracy: 0.9537\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1582 - accuracy: 0.9552 - val_loss: 0.1598 - val_accuracy: 0.9547\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1553 - accuracy: 0.9562 - val_loss: 0.1581 - val_accuracy: 0.9562\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1528 - accuracy: 0.9571 - val_loss: 0.1558 - val_accuracy: 0.9557\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1503 - accuracy: 0.9578 - val_loss: 0.1539 - val_accuracy: 0.9575\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1478 - accuracy: 0.9585 - val_loss: 0.1516 - val_accuracy: 0.9570\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1453 - accuracy: 0.9588 - val_loss: 0.1490 - val_accuracy: 0.9588\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1431 - accuracy: 0.9599 - val_loss: 0.1475 - val_accuracy: 0.9580\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1406 - accuracy: 0.9604 - val_loss: 0.1462 - val_accuracy: 0.9583\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1384 - accuracy: 0.9614 - val_loss: 0.1441 - val_accuracy: 0.9607\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1359 - accuracy: 0.9619 - val_loss: 0.1435 - val_accuracy: 0.9615\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1339 - accuracy: 0.9626 - val_loss: 0.1423 - val_accuracy: 0.9612\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 3s 62us/sample - loss: 0.1318 - accuracy: 0.9630 - val_loss: 0.1390 - val_accuracy: 0.9618\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 3s 49us/sample - loss: 0.1301 - accuracy: 0.9635 - val_loss: 0.1380 - val_accuracy: 0.9618\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 45us/sample - loss: 0.1279 - accuracy: 0.9640 - val_loss: 0.1363 - val_accuracy: 0.9627\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1260 - accuracy: 0.9646 - val_loss: 0.1351 - val_accuracy: 0.9623\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1241 - accuracy: 0.9654 - val_loss: 0.1339 - val_accuracy: 0.9635\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1222 - accuracy: 0.9660 - val_loss: 0.1338 - val_accuracy: 0.9630\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 3s 49us/sample - loss: 0.1205 - accuracy: 0.9665 - val_loss: 0.1314 - val_accuracy: 0.9640\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1186 - accuracy: 0.9673 - val_loss: 0.1304 - val_accuracy: 0.9650\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1171 - accuracy: 0.9674 - val_loss: 0.1282 - val_accuracy: 0.9647\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.1152 - accuracy: 0.9679 - val_loss: 0.1278 - val_accuracy: 0.9653\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1136 - accuracy: 0.9682 - val_loss: 0.1261 - val_accuracy: 0.9660\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.1120 - accuracy: 0.9688 - val_loss: 0.1250 - val_accuracy: 0.9658\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1102 - accuracy: 0.9692 - val_loss: 0.1234 - val_accuracy: 0.9662\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1089 - accuracy: 0.9696 - val_loss: 0.1227 - val_accuracy: 0.9662\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1072 - accuracy: 0.9699 - val_loss: 0.1219 - val_accuracy: 0.9677\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1059 - accuracy: 0.9704 - val_loss: 0.1212 - val_accuracy: 0.9675\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.1044 - accuracy: 0.9705 - val_loss: 0.1194 - val_accuracy: 0.9668\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1029 - accuracy: 0.9713 - val_loss: 0.1185 - val_accuracy: 0.9672\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.1016 - accuracy: 0.9717 - val_loss: 0.1186 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 3s 51us/sample - loss: 0.1002 - accuracy: 0.9722 - val_loss: 0.1164 - val_accuracy: 0.9685\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.0988 - accuracy: 0.9722 - val_loss: 0.1161 - val_accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
