{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Exercises: Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 0. Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from scipy.stats import expon, reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def load_housing_data():\n",
    "    housing_path = 'datasets/housing/housing.csv'\n",
    "    return pd.read_csv(housing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "income_cat = pd.cut(housing[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "y = housing[\"median_house_value\"].values\n",
    "X = housing.drop('median_house_value', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=income_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 17606 to 15775\n",
      "Data columns (total 9 columns):\n",
      "longitude             16512 non-null float64\n",
      "latitude              16512 non-null float64\n",
      "housing_median_age    16512 non-null float64\n",
      "total_rooms           16512 non-null float64\n",
      "total_bedrooms        16354 non-null float64\n",
      "population            16512 non-null float64\n",
      "households            16512 non-null float64\n",
      "median_income         16512 non-null float64\n",
      "ocean_proximity       16512 non-null object\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X.select_dtypes(include=self.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_rooms_per_household=True, add_population_per_household=True,\n",
    "                 add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        if add_rooms_per_household:\n",
    "            rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "            X = np.c_[X,rooms_per_household]\n",
    "        if add_population_per_household:\n",
    "            population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "            X = np.c_[X,population_per_household]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            X = np.c_[X,bedrooms_per_room]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 2 and the array at index 1 has size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-80c39168e98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 2 and the array at index 1 has size 0"
     ]
    }
   ],
   "source": [
    "np.c_[X, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline_num = Pipeline([\n",
    "    ('selector', TypeSelector('float')),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attr_adder', CombinedAttributesAdder()),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "pipeline_cat = Pipeline([\n",
    "    ('selector', TypeSelector('object')),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "pipeline_X = FeatureUnion([('numeric', pipeline_num), ('categorical', pipeline_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "n_jobs = cpu_count() - 1\n",
    "print(n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try a Support Vector Machine regressor ( sklearn.svm.SVR ) with various hyperparameters, such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Donâ€™t worry about what these hyperparameters mean for now. How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Wrong approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Running the pipeline prior to cross-validation underestimates the generalization error and overestimates the generalization performance of a model, as statistics from the validation data leak into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=11)]: Done 100 out of 100 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=11,\n",
       "             param_grid=[{'C': [0.1, 1.0, 10.0, 100.0], 'kernel': ['linear']},\n",
       "                         {'C': [0.1, 1.0, 10.0, 100.0],\n",
       "                          'gamma': [0.01, 0.1, 1.0, 10], 'kernel': ['rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed = pipeline_X.fit_transform(X_train)\n",
    "X_test_processed = pipeline_X.transform(X_test)\n",
    "sv_reg = SVR()\n",
    "param_grid = [{'kernel':['linear'], 'C': [0.1, 1.0, 10., 100.]},\n",
    "              {'kernel': ['rbf'], 'C': [0.1, 1.0, 10., 100.], 'gamma': [0.01, 0.1, 1.0, 10]}]\n",
    "grid_search_leakage = GridSearchCV(sv_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=n_jobs, verbose=2)\n",
    "grid_search_leakage.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72128.10683248386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_mse = grid_search_leakage.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_leakage.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Right approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To do cross-validation correctly, the entire data processing steps should be re-executed for each fold so that the estimation properly takes into account that the test data is unknown at training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_pipe = Pipeline([('feature_pipeline?', pipeline_X),('svr', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_grid = [{'svr__kernel':['linear'], 'svr__C': [0.1, 1.0, 10., 100.]},\n",
    "              {'svr__kernel': ['rbf'], 'svr__C': [0.1, 1.0, 10., 100.], 'svr__gamma': [0.01, 0.1, 1.0, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=11)]: Done 100 out of 100 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('feature_pipeline',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('numeric',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('selector',\n",
       "                                                                                         TypeSelector(dtype='float')),\n",
       "                                                                                        ('imputer',\n",
       "                                                                                         SimpleImputer(add_indicator=False,\n",
       "                                                                                                       copy=True,\n",
       "                                                                                                       fill_value=None,\n",
       "                                                                                                       missing_values=nan,\n",
       "                                                                                                       strategy='median',\n",
       "                                                                                                       verbose=0))...\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=11,\n",
       "             param_grid=[{'svr__C': [0.1, 1.0, 10.0, 100.0],\n",
       "                          'svr__kernel': ['linear']},\n",
       "                         {'svr__C': [0.1, 1.0, 10.0, 100.0],\n",
       "                          'svr__gamma': [0.01, 0.1, 1.0, 10],\n",
       "                          'svr__kernel': ['rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(model_pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=n_jobs, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72130.35304275915"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 100.0, 'svr__kernel': 'linear'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69934.21552363789"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try replacing `GridSearchCV` with `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_distributions = {'svr__kernel':['linear', 'rbf'], 'svr__C': reciprocal(1., 10000.), 'svr__gamma': expon(scale=1.)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=11)]: Done 140 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=11)]: Done 343 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=11)]: Done 500 out of 500 | elapsed: 20.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('feature_pipeline',\n",
       "                                              FeatureUnion(n_jobs=None,\n",
       "                                                           transformer_list=[('numeric',\n",
       "                                                                              Pipeline(memory=None,\n",
       "                                                                                       steps=[('selector',\n",
       "                                                                                               TypeSelector(dtype='float')),\n",
       "                                                                                              ('imputer',\n",
       "                                                                                               SimpleImputer(add_indicator=False,\n",
       "                                                                                                             copy=True,\n",
       "                                                                                                             fill_value=None,\n",
       "                                                                                                             missing_values=nan,\n",
       "                                                                                                             strategy='median',\n",
       "                                                                                                             verbo...\n",
       "                   iid='warn', n_iter=100, n_jobs=11,\n",
       "                   param_distributions={'svr__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f41a07070d0>,\n",
       "                                        'svr__gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f41a07071d0>,\n",
       "                                        'svr__kernel': ['linear', 'rbf']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(model_pipe, param_distributions, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   n_jobs=n_jobs, verbose=2, n_iter=100, random_state=42)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60260.71135638083"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_mse = random_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 9502.32435013483,\n",
       " 'svr__gamma': 0.19349404041660798,\n",
       " 'svr__kernel': 'rbf'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_test_pred = random_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58779.2325235463"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Simple approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This approach calculates the feature importance based on the best model, as determined before. This ignores that the best model might be different if feature selection was performed during the parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if model.get_params('kernel') == 'linear':\n",
    "    feature_importance = model.coef_\n",
    "else:\n",
    "    feature_importance = permutation_importance(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "selection_pipe = Pipeline([('feature_pipeline', pipeline_X),('select', SelectKBest(feature_importance), ('svr', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "selection_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Comprehensive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The SVR with a kernel other then linear does not have any method to determine the importance of features. A general method to guess this would be to use the permutation importance. As this calculation requires cross-validation, the procedure is computationally quite demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class selectSVR(SVR):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        super().fit(X, y, sample_weight)\n",
    "        if clf.get_params()['kernel'] != 'linear':\n",
    "            perm_imp = permutation_importance(self, X.todense(), y, n_jobs=1)\n",
    "            self.permutation_importances_ = perm_imp['mean_permutation_importance']\n",
    "        return self\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        if clf.get_params()['kernel'] != 'linear':\n",
    "            return self.permutation_importances_\n",
    "        else:\n",
    "            return self.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class fitSVR(SVR):\n",
    "    def __init__(self):\n",
    "        super().__init__(self, self.named_steps['select'].get_params()['estimator'].get_params())\n",
    "    def get_params(self, deep=True):\n",
    "        super().get_params(self, deep)\n",
    "    def set_params(self, **params):\n",
    "        super().set_params(self, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "selection_pipe = Pipeline([('feature_pipeline', pipeline_X),('select', SelectFromModel(selectSVR())),('svr', fitSVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_distributions = {'select__kernel':['linear', 'rbf'], 'select__C': reciprocal(1., 10000.), 'select__gamma': expon(scale=1.)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try creating a single pipeline that does the full data preparation plus the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Already done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Automatically explore some preparation options using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline_num = Pipeline([\n",
    "    ('selector', TypeSelector('float')),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attr_adder', CombinedAttributesAdder()),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "pipeline_cat = Pipeline([\n",
    "    ('selector', TypeSelector('object')),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "pipeline_X = FeatureUnion([('numeric', pipeline_num), ('categorical', pipeline_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2802ccf6411a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mselection_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_pipeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'svr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_importance' is not defined"
     ]
    }
   ],
   "source": [
    "selection_pipe = Pipeline([('feature_pipeline', pipeline_X),('select', SelectKBest(feature_importance)), ('svr', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "prep_grid = {'feature_pipeline__numeric__imputer__strategy': ['median', 'mean', 'most_frequent'],\n",
    "             'feature_pipeline__numeric__attr_adder__add_rooms_per_household': [True, False],\n",
    "              'feature_pipeline__numeric__attr_adder__add_population_per_household': [True, False],\n",
    "              'feature_pipeline__numeric__attr_adder__add_bedrooms_per_room': [True, False],\n",
    "              'feature_pipeline__categorical__encoder': [OneHotEncoder(), OrdinalEncoder()],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "param_grid = [{'svr__kernel':['linear'], 'svr__C': [100., 1000., 10000, 100000.]}.update(prep_grid),\n",
    "              {'svr__kernel': ['rbf'], 'svr__C': [100., 1000., 10000, 100000.], 'svr__gamma': [0.01, 0.1, 1.0]}.update(prep_grid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model_pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=n_jobs, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
